# Lecture 11

## Review for that class I slept through

* Thread = steam of instructions and its associated state
  * We can have multiple thread within a single process
  * Collaborative instead of competitive
* Process = has a singular address space
  * Competitve instead of cooperative 
* Since their is cooperation with explicit sharing, we can access data that is contained in the RAM simply
* Why dont we care about performance with threads?
  * Security, if we have one process with every thing being a thread, they all share the same memory and can have access to things they should not

* The WWW is a clinet-server architecture where the client (a browser) makes a request of a server via HTTP
* HTTP is stateless - The webserver for each request has no memory of the other requests, even from the same client
  * This is why we have cookies and session ids - the serer can use that to identify the same client over time

* Why threading over process?
  * Better performance

* Why processes over threading?
  * Isolation and robustness against classes
 
## Parallelism in a web server

* It seems that a webserver is parallel - all client work can be dome at the same time
* Then we could choose the faster threads over proesses for speed. Or the isolated process for security
* Could we share smoething between workers to make threads more appealing?
 
* Cache - specialized storage relative to main memory used to grab commonly used

### User threads vs Kernel threads

![image](https://github.com/Clester31/1550-notes/assets/91839534/2a44c906-a896-4b33-8a07-a2716f994f45)

* Two ways the OS can deal with threads
  * Assume: pre-emptive multi-tasking modern OS
  * User-threading (Left | AKA: Green-threading)
    * We have a data structure that trakcs our process
    * The management of threads in process is done by a library held in user space. It contains the thread state
    * When we call pthread - create
      * Create a new thread within our process and add another thread state 
  * Kernel-threading (Right)
    * We have a process table with two entries
    * When we call pthread - create
    * We have a data structure that holds the state of our threads and process
      * Create a new thread within our process 
      * We have to do a system call because we are now running kernel code to update the thread state

#### Infinte loop example

* Kernel Threads
  * Preemption occurs, and the next process is set to ready and something is scheduled
  * After running the other process, we go back to the original thread
  * Yielding isn't necessary for proper operation, 
 
* User Threads
  * we are still a preemptive multi tasking system, taking us into the OS.
  * We invoke the scheduler again and run the left-most process
  * The other threads/process don't get a chance to run. Their resources will be denied CPU time (starvation)
 
* Kernel thread when it runs a blocking system call like read()
 * System call invokes the OS
 * OS sets the thread state to blocked
 * Run the scheduler and picke which ever thread is ready to run

* When the user thread makes a system call, the OS will have no choice but to block the entire process 

#### More about User vs Kernel Threads

* User Threads
  * User-space library responsible for providing threading support
    * Threading operations are library (function) calls
  * Greedy threads (CPU time) may **starve** our other threads in the same process
  * A thread doing blocking IO may make the entire process block
 
* Kernel Threads
  * OS provides support fo the threads natively
    * Threading operations are system calls
  * The OS manages threads as it does process, with preemption and scheduling
 
* Pthread - yield
 * Calls the scheduler to move its process back to a ready state
 * This is done to prevent starvation and give CPU time to another thread
