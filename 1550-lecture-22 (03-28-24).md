# Lecture 22

## Review on Deadlock

* Deadlock is independent of whether whe have synchronization primatives or not
  * Can still happen even if our primitives work
* 4 things need to be true for deadlock to occur
  * Mutual exclusion (resouce)
    * How can we attack mutual exclusion - spooling (queueing) 
  * Hold and wait (program) - Process wants two (or more) resources, but the other one is non-premptable, is being used by something else, and we can't share it
    * What do we do when waiting for the other resource? - just hold on to the resources we have
    * How to prevent?
      * write in a style that avoids hold and wait. use two phase locking
        * Imagine trying to acquire 10 resources, say you acquire the first 7 but can't get the 8th
        * Instead of holding onto the 7 you have while waiting, drop all 7 you have and start from the beginning  
  * No preemption (resource)
    * Why do we ignore this? too much work to preempt a process and bring it back  
  * Circular wait
    * How to prevent?
      * get rid of the back edge; get rid of the loop
* “A set of processes is deadlocked if each process in the set is waiting for an event that only another process in the set can cause.”
* Non-preemptability: We can't forcibly take something away to give it to someone else

### What to do in an OS about deadlock?

* Ignore
  * Ostrich Algorithm - pretend like the problem didn't happen
  * Cost/Benefits - Deadlock in a modern computer is not as fatal as it's made out to be. Can be easily dealt with if it happens
* Detect and Recover
  * Too late, no good options (kill process?)
* Avoid
  * Requires knowing future behavior of programs otherwise devolves into batch schedule (already deadlock free)
* Prevent
  * Make at least one of the four conditions always false
  * Probably mutual exclusion via spooling (like a queue)       

## Memory Management

### Why do we manage memory (RAM)?

* It is a limited resource
* It is **volatile** has an associated cost to it, but is necessary for all programs to do their work
* We wish to shar eit
  * If we don't, the von Neumann architecture won't let us do any of the things we did in the first part of the course
 
### Exclusive Access

* In previous times, we didn't have enough RAM to share
* Thus every program had all of RAM (or what was leftover from the OS) to itself

#### Degree of Multiprogramming

* The more IO-bound our workload, the more processes we need to run to saturate the CPU's time
* THe more processes we need to run, the more we must share RAM

### Fixed Patritions

* We can divide up RAM (partition) into chunks of fixed size and allocate new processes to one of these partitions
* Partition size probably can't change while the systme is on
* But at least now we're sharing

![image](https://github.com/Clester31/1550-notes/assets/91839534/44ad34af-f154-4a5d-b437-5b1040039509)

### Problems

* Protection Problem
  * Now that we are sharing memory, how do we make sure that our process doesn't read or write the memory that belongs to another - and make sure they don't do that for us?
  * Many solutions, but we want virtualization 

* Relocation Problem
  * What if a program were to move in RAM?
  * When could it move
    * Between executions
    * During execution?
   
* Absolute:
  ```
  $pc = addr
  J addr
  ```
* Relative
  ```
  $pc += offset
  BEQ rs, rt, 8
  ```

### Sharing with Patritions
* To solve the protection problem for the partitioning memory by storing the extends of the partitino and checking all accesses against it
* Where must this check be done?

* We can solve the relocation problem by turning absolute adresses into relative addresses by adding the base to them

### Swapping

* The only way to create the illusion of more memory is by swapping - moving code disk and data from RAM to disk
* In a VN architecture, if we swap the entire process memory, we lost eh ability to run the program, so it's effectively paused
* When we bring it back in, it may not be in the smae location it started out in
