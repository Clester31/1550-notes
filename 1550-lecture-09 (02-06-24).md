# Lecture 9

## Review

* Using CPU's time is like animation, it gives the illusion that one process is happening at a time
* Programs don't simply run:
  * They start at the ready, meaning we have all the resources needed to run exceot the CPU's time
  * We choose what process is ready to run next and we go into the running state
  * On normal termination, we enter the exit() state
    * exit does not return anything back to the caller
   
* Juggling analogy (moving from a batch model to a pseudo-parallel system)
  * How to deal with two balls in one hand
  * We must transfer the data into RAM before transforming it
  * If the data is not in RAM and we need it, we need to ask for that transfer to begin, which will take a noticable amount of time
  * The program will do a block() system call to wait and get data into RAM
    * It's like a waiting room, you do other work while you wait for something else
  * The only process that can be scheduled are ready processes
  * moving data can happen simultaneously as it does not deal with the CPU
 
* How do we know the data transfer is done?
  * change a variable in the data structure within the OS
  * We first stop the running process and switch to the OS so we can mark a process as read (interrupt)
 
## The Bus 

* Hears everything, but only listen to the things that matter
* Hard Drive will write data and the RAM is listening for specific data from RAM addresses
* What the processor does while waiting
  * Set process A to ready
  * Set process B to ready
  * Run the scheduler
* The process that is blocked is now ready

* Programs that take a long time on the CPU, will once in a while, make a system call to run the scheduler
  * yield() system call
* We preempt the regularly scheduled program to move into the OS
